import {
  calculateTargetMessageCount,
  GESPREK_TURNS_PER_BATCH,
} from "@/config";
import { Deelnemer } from "@/data/deelnemers";
import { getRandomModelConfig } from "@/lib/ai";
import { generateObject } from "ai";
import { z } from "zod";
import { addTimestampsToMessages } from "../utils";
import { createLogger } from "@/lib/logger";

const logger = createLogger("genereer-gesprek-berichten");

// Constants for conversation context management
const CONTEXT_THRESHOLD = 15; // Show summary when conversation has >15 messages
const LEAST_ACTIVE_THRESHOLD = 3; // Minimum message count to be considered "active"
const MAX_TURNS_TO_USE = 3; // Maximum turns to use from AI response (even if it generates more)
const LAST_BATCH_THRESHOLD = 10; // Remaining messages threshold to trigger last batch mode

/**
 * Calculate how many recent messages to show for reactions based on participant count
 * More participants = need more context to see variety
 */
function calculateRecentMessagesCount(participantCount: number): number {
  return Math.min(10, Math.max(5, participantCount));
}

export type GeneratedMessage = {
  message: string;
  deelnemerName: string;
  deelnemerId: number;
};

/**
 * Generate an intro message from the user who started the conversation
 */
function generateIntroMessage(onderwerp: string): string {
  const variations = [
    `Beste politici, ik wil graag dat jullie het hebben over: ${onderwerp}`,
    `Goedendag, kunnen jullie jullie standpunten delen over ${onderwerp}?`,
    `Ik zou graag jullie mening horen over ${onderwerp}`,
    `Kunnen we het vandaag hebben over ${onderwerp}?`,
    `Ik start deze discussie over: ${onderwerp}. Wat vinden jullie?`,
  ];
  
  // Select a random variation
  return variations[Math.floor(Math.random() * variations.length)];
}

type AIGeneratedMessage = {
  deelnemerName: string;
  messages: string[]; // 1-3 berichten per burst
};

/**
 * Build a Zod schema for the messages that can be generated by the AI, linked to enumerate of available deelnemers.
 * @param deelnemers - The deelnemers of the conversation.
 * @returns A Zod schema for the messages of the conversation.
 */
export function buildMessageSchema(deelnemers: Deelnemer[]) {
  const deelnemerNames = deelnemers.map((d) => d.name);

  const MIN_TURNS = 2;
  const MAX_TURNS = 10; // Ruime limiet voor schema, we truncaten naar 3 in code
  const MIN_MESSAGES_PER_TURN = 1;
  const MAX_MESSAGES_PER_TURN = 3;

  return z
    .array(
      z
        .object({
          deelnemerName: z
            .enum(deelnemerNames as [string, ...string[]])
            .describe(
              `De naam van de politicus die deze berichten verstuurt. Moet een van de volgende zijn: ${deelnemerNames.join(
                ", "
              )}`
            ),
          messages: z
            .array(z.string())
            .min(MIN_MESSAGES_PER_TURN)
            .max(MAX_MESSAGES_PER_TURN)
            .describe(
              `Array van ${MIN_MESSAGES_PER_TURN} tot ${MAX_MESSAGES_PER_TURN} korte chat-berichten van deze politicus. MEESTAL 1 bericht, SOMS 2 berichten, ZELDEN 3 berichten. Minder is meer! Elk bericht is zeer kort (1 zin of minder).`
            ),
        })
        .describe("Een enkele beurt: één politicus die 1-3 berichten stuurt")
    )
    .min(MIN_TURNS)
    .max(MAX_TURNS)
    .describe(
      `Array van gespreksbeurten. Bij voorkeur 2-3 beurten. Elke beurt = één politicus die reageert met 1-3 berichten.`
    );
}

/**
 * Flatten AI generated message bursts into individual messages and add deelnemer IDs.
 * Each burst (1-3 messages from one politicus) becomes multiple individual GeneratedMessage objects.
 * @param bursts - The generated message bursts from the AI.
 * @param deelnemers - The deelnemers of the conversation.
 * @returns Flattened array of individual messages with deelnemer IDs.
 */
export function addDeelnemerIdsToAIGeneratedMessages(
  bursts: AIGeneratedMessage[],
  deelnemers: Deelnemer[]
): GeneratedMessage[] {
  const deelnemerNameToId = Object.fromEntries(
    deelnemers.map((d) => [d.name, d.id])
  );

  // Flatten bursts into individual messages
  const flattenedMessages: GeneratedMessage[] = [];

  for (const burst of bursts) {
    const deelnemerId = deelnemerNameToId[burst.deelnemerName];

    for (const message of burst.messages) {
      flattenedMessages.push({
        message,
        deelnemerName: burst.deelnemerName,
        deelnemerId,
      });
    }
  }

  return flattenedMessages;
}

/**
 * Build role and objective section
 */
function buildRoleSection(onderwerp: string): string {
  return `
    # Rol
    Je bent een expert in het schrijven van realistische Nederlandse politieke onderhandelingen. 
    Politici proberen tot overeenstemming te komen, maar dit lukt niet altijd.
    Wees eerlijk over fundamentele ideologische verschillen die niet te overbruggen zijn.
    
    # Onderwerp
    ${onderwerp}
    
    ⚠️ BELANGRIJK: Het onderwerp is "${onderwerp}". 
    Politici mogen hun ideologie inbrengen en soms zijwegen nemen (dat is menselijk en soms grappig).
    Maar zorg dat discussies een logische link hebben met het onderwerp - dwaal niet meteen volledig af.`;
}

/**
 * Build deelnemers section with their details
 */
function buildDeelemersSection(sortedDeelnemers: Deelnemer[]): string {
  return `
    
    # Deelnemers (gesorteerd op zetels)
    ${sortedDeelnemers
      .map(
        (deelnemer) => `
    - ${deelnemer.name}
      - Partij: ${deelnemer.partij.name} (${deelnemer.partij.zetels} zetels)
      - Tone of voice: ${deelnemer.toneOfVoice}${
          deelnemer.persoonlijkeDetails
            ? `\n      - Achtergrond: ${deelnemer.persoonlijkeDetails}`
            : ""
        }${
          deelnemer.typischeUitspraken &&
          deelnemer.typischeUitspraken.length > 0
            ? `\n      - Typische uitspraken: ${deelnemer.typischeUitspraken.join(
                "; "
              )}`
            : ""
        }
      - Standpunten:
          ${deelnemer.partij.programma.standpunten
            .map((standpunt) => `- ${standpunt}`)
            .join("\n          ")}
    `
      )
      .join("\n")}`;
}

/**
 * Build zetelverdeling section
 */
function buildZetelverdeling(sortedDeelnemers: Deelnemer[]): string {
  const totalZetels = sortedDeelnemers.reduce(
    (sum, d) => sum + d.partij.zetels,
    0
  );
  const majorityNeeded = 76;

  return `
    
    # Zetelverdeling & Machtsbalans
    - Totaal zetels aan tafel: ${totalZetels}
    - Meerderheid nodig: ${majorityNeeded} zetels
    - Grootste partij: ${sortedDeelnemers[0].partij.name} (${
    sortedDeelnemers[0].name
  }, ${sortedDeelnemers[0].partij.zetels} zetels)
    - Kleinste partij: ${
      sortedDeelnemers[sortedDeelnemers.length - 1].partij.name
    } (${sortedDeelnemers[sortedDeelnemers.length - 1].name}, ${
    sortedDeelnemers[sortedDeelnemers.length - 1].partij.zetels
  } zetels)
    
    Politici kunnen zetels strategisch inzetten:
    - Grote partijen (>20 zetels): mandaat benadrukken
    - Kleine partijen: unieke positie als "kingmaker"
    - Coalitiekansen benoemen
    - Realisme tonen over macht`;
}

/**
 * Build chat-style format section
 */
function buildChatStyleSection(): string {
  return `
    
    # Chat-stijl Format
    - Dit is een GROEPSCHAT. Politici sturen korte berichten zoals in WhatsApp
    - Per beurt 1-3 berichten:
      * MEESTAL 1 bericht (korte reactie)
      * SOMS 2 berichten (uitgebreider)
      * ZELDEN 3 berichten (complex punt)
    - Berichten zijn ZEER KORT (meestal 1 korte zin, max 15-20 woorden)
    - INFORMELE TOON: Gebruik ALTIJD voornamen, NOOIT achternamen
      * Spreek elkaar aan met voornaam (bijv. "Geert", "Jesse", "Dilan")
      * Je mag ook direct reageren zonder naam te noemen
      * NOOIT achternamen gebruiken (dus niet "Wilders" of "Klaver")
    - Emojis: spaarzaam, vooral door jongere politici (Rob Jetten, Laurens Dassen)`;
}

/**
 * Build reactive flow section
 */
function buildReactiveFlowSection(participantCount: number): string {
  const largeGroupGuidance = participantCount > 8 
    ? `\n    - Bij grote groepen (${participantCount} politici): NIET iedereen reageert op alles
    - Subgroepen mogen ontstaan (bijv. klimaatblok vs anti-klimaatblok)
    - Sommige politici blijven stil als het onderwerp niet hun kernthema is`
    : "";

  return `
    
    # Reactieve Flow & Diepgang
    - Politici reageren INHOUDELIJK op wat er net gezegd is, niet alleen met "eens!" of "onzin!"
    - Stel kritische vragen: "Hoe financier je dat?" "Wat als X gebeurt?"
    - Bepaal logisch wie getriggerd wordt:
      * Tegenpolen: Wilders ↔ Klaver (klimaat/migratie), VVD ↔ SP (economie)
      * Coalitiegenoten steunen elkaar maar hebben ook eigen agenda
    - Bij fundamentele verschillen: blijf bij je principes, geef niet zomaar toe${largeGroupGuidance}`;
}

/**
 * Build Kamer bevoegdheden section
 */
function buildKamerBevoegdhedenSection(): string {
  return `
    
    # Kamer Bevoegdheden
    
    ✅ WEL: Moties, wetsvoorstellen, begrotingswijzigingen, hoorzittingen
    ❌ NIET: Direct onderhandelen met bedrijven, uitvoerende taken
    
    Gebruik realistische instrumenten:
    - "Ik dien een motie in..."
    - "We kunnen via de begroting..."
    - "Laten we wetgeving aanpassen..."`;
}

/**
 * Build time context section with current date and days since election
 */
function buildTimeContextSection(): string {
  const electionDate = new Date("2025-10-29");
  const today = new Date();
  
  // Calculate days since election
  const diffTime = today.getTime() - electionDate.getTime();
  const daysSinceElection = Math.floor(diffTime / (1000 * 60 * 60 * 24));
  
  // Format current date
  const options: Intl.DateTimeFormatOptions = { 
    year: 'numeric', 
    month: 'long', 
    day: 'numeric',
    weekday: 'long'
  };
  const formattedDate = today.toLocaleDateString('nl-NL', options);
  
  return `
    
    # Tijdscontext
    - Vandaag: ${formattedDate}
    - Verkiezingen: 29 oktober 2025
    - Dagen sinds verkiezingen: ${daysSinceElection} dagen
    
    Dit is relevant voor de context en urgentie van de onderhandelingen.`;
}

/**
 * Build user prompt for the AI
 */
function buildUserPrompt(options: {
  conversationContext: string;
  lastSpeakerContext: string;
  speakerDistributionContext: string;
  phase: "begin" | "midden" | "einde";
  phaseInstructions: string;
  isLastBatch: boolean;
}): string {
  const baseTurnInstructions = options.isLastBatch
    ? "⚠️ DIT IS HET LAATSTE STUK - GENEREER 2 OF 3 BEURTEN ⚠️\n\nHet gesprek moet REALISTISCH eindigen. Kies wat past bij de discussie:\n" +
      "- Compromis als standpunten dicht bij elkaar lagen\n" +
      "- Patstelling als fundamentele verschillen onoverbrugbaar zijn\n" +
      "- Deelakkoord met kanttekeningen\n" +
      "- 'We praten verder' als geen akkoord mogelijk is"
    : "⚠️ GENEREER 2 OF 3 BEURTEN ⚠️";

  return `${options.conversationContext}${options.lastSpeakerContext}${options.speakerDistributionContext}

## Fase: ${options.phase.toUpperCase()}
${options.phaseInstructions}

${baseTurnInstructions}

Aantal beurten: 2 of 3
Berichten per beurt: MEESTAL 1, SOMS 2, ZELDEN 3
Maximum 3 politici mogen reageren.

WIE zou logisch reageren op de LAATSTE BERICHTEN? Overweeg:
- Wie wordt getriggerd door wat er in de LAATSTE BERICHTEN gezegd is?
- Reageer INHOUDELIJK op die specifieke berichten (niet alleen "eens!" of "onzin!")
- Stel kritische vragen om standpunten uit te dagen
- Blijf grotendeels bij het onderwerp, maar afdwalen naar gerelateerde punten mag (is soms grappig en realistisch)
${options.isLastBatch ? "- Laat het gesprek natuurlijk afronden met een REALISTISCHE uitkomst" : ""}`;
}

/**
 * Build conversation summary context
 */
function buildConversationSummaryContext(
  messageCount: number,
  onderwerp: string
): string {
  if (messageCount > CONTEXT_THRESHOLD) {
    return `\n## Context:\nEr zijn al ${messageCount} berichten uitgewisseld. Het gesprek over "${onderwerp}" is in volle gang.\n\n⚠️ LET OP: Reageer ALLEEN op de LAATSTE BERICHTEN hieronder, niet op eerdere discussiepunten.\n`;
  } else if (messageCount > 0) {
    return `\n## Context:\nHet gesprek heeft ${messageCount} berichten. Reageer ALLEEN op de LAATSTE BERICHTEN hieronder.\n`;
  }
  return "";
}

/**
 * Build last speaker context (recent messages)
 */
function buildLastSpeakerContext(
  recentMessages: GeneratedMessage[]
): string {
  if (recentMessages.length === 0) return "";

  return `\n## ⚠️ LAATSTE BERICHTEN - DIT IS ALLES WAT JE HEBT:\n${recentMessages
    .map((m, i) => `[${i + 1}] ${m.deelnemerName}: "${m.message}"`)
    .join("\n")}\n\n🚨 KRITIEKE REGEL: Reageer UITSLUITEND op wat HIERBOVEN staat. NIETS anders.

Checklist voor ELKE reactie:
1. Als je iemand bij naam noemt: staat die persoon hierboven? ✓
2. Als je een argument bekritiseert: staat dat argument hierboven? ✓
3. Als je zetels noemt: is dat relevant voor wat hierboven gezegd is? ✓
`;
}

/**
 * Build speaker distribution context
 */
function buildSpeakerDistributionContext(
  deelnemers: Deelnemer[],
  speakerCounts: Map<string, number>
): string {
  const deelnemersBySpeechCount = deelnemers
    .map((d) => ({
      name: d.name,
      count: speakerCounts.get(d.name) || 0,
    }))
    .sort((a, b) => a.count - b.count);

  const leastActiveDeelnemers = deelnemersBySpeechCount
    .filter((d) => d.count < LEAST_ACTIVE_THRESHOLD)
    .map((d) => d.name);

  if (leastActiveDeelnemers.length > 0) {
    return `\n## BELANGRIJK - Sprekersverdeling:\nDeze politici hebben nog weinig gesproken: ${leastActiveDeelnemers.join(", ")}\nVarieer de sprekers!\n`;
  }
  return "\n## BELANGRIJK - Sprekersverdeling:\nVarieer de sprekers! Laat ook andere politici aan het woord.\n";
}

/**
 * Build the system message for the AI.
 * @param opties - The options for the conversation.
 * @returns The system message for the AI.
 */
const buildSystemMessage = (opties: {
  onderwerp: string;
  deelnemers: Deelnemer[];
}) => {
  const sortedDeelnemers = [...opties.deelnemers].sort(
    (a, b) => b.partij.zetels - a.partij.zetels
  );

  return (
    buildRoleSection(opties.onderwerp) +
    buildTimeContextSection() +
    buildDeelemersSection(sortedDeelnemers) +
    buildZetelverdeling(sortedDeelnemers) +
    buildChatStyleSection() +
    buildReactiveFlowSection(opties.deelnemers.length) +
    buildKamerBevoegdhedenSection()
  );
};

export async function genereerGesprekBerichten(opties: {
  onderwerp: string;
  deelnemers: Deelnemer[];
  startAt: Date;
  endAt: Date;
}) {
  const generatedMessages: GeneratedMessage[] = [];
  
  // Add intro message from the user who started the conversation
  const introMessage: GeneratedMessage = {
    message: generateIntroMessage(opties.onderwerp),
    deelnemerName: "U", // The user who started the conversation
    deelnemerId: 0, // Special ID for the conversation starter
  };
  generatedMessages.push(introMessage);
  
  const systemPrompt = buildSystemMessage(opties);

  let phase: "begin" | "midden" | "einde" = "begin";
  let batchCount = 0;

  // Calculate target message count based on number of participants
  const targetMessageCount = calculateTargetMessageCount(opties.deelnemers.length);
  const recentMessagesCount = calculateRecentMessagesCount(opties.deelnemers.length);

  logger.info(
    `Generating ~${targetMessageCount} messages in batches of ${GESPREK_TURNS_PER_BATCH} turns (kleinere batches voor natuurlijker gesprek)`,
    { phase, participants: opties.deelnemers.length, targetMessages: targetMessageCount }
  );

  // Start from 1 since we already have the intro message
  while (generatedMessages.length < targetMessageCount + 1) {
    batchCount++;

    const progress = (generatedMessages.length - 1) / targetMessageCount;

    if (progress < 0.3) {
      phase = "begin";
    } else if (progress < 0.6) {
      phase = "midden";
    } else {
      phase = "einde";
    }

    const remainingMessages = targetMessageCount + 1 - generatedMessages.length;

    const isLastBatch = remainingMessages <= LAST_BATCH_THRESHOLD;

    logger.debug(
      `Generating batch ${batchCount} with ${GESPREK_TURNS_PER_BATCH} turns (${remainingMessages} messages remaining)`,
      { phase, remainingMessages }
    );

    // Build context for AI prompt
    const conversationSummaryContext = buildConversationSummaryContext(
      generatedMessages.length,
      opties.onderwerp
    );

    const phaseInstructions = {
      begin:
        "Dit is het BEGIN van het gesprek. Een gebruiker heeft het onderwerp geïntroduceerd. Laat de politici nu reageren en hun standpunten helder uiteenzetten. Toon waar ze van elkaar verschillen.",
      midden:
        "Dit is het MIDDEN van het gesprek. De discussie wordt dieper. Politici stellen kritische vragen, uiten bezwaren, en beginnen de kern van hun fundamentele verschillen bloot te leggen. Toon realistische spanning en echte dilemma's.",
      einde:
        "Dit is het EINDE van het gesprek. Laat de politici REALISTISCH eindigen. Mogelijke uitkomsten:\n" +
        "- COMPROMIS: Als standpunten dicht bij elkaar liggen, kan er een akkoord komen\n" +
        "- PATSTELLING: Bij fundamentele verschillen blijft discussie vastlopen (bijv. Wilders vs Klaver over klimaat/migratie)\n" +
        "- DEELAKKOORD: Overeenstemming op deelpunten, maar kernverschillen blijven bestaan\n" +
        "- DOORPRATEN: 'We blijven het oneens, maar praten verder'\n\n" +
        "Wees EERLIJK over ideologische kloven. Niet alles is oplosbaar. Bij grote groepen (>8) mogen subgroepen ontstaan die onderling discussiëren.",
    };

    const recentMessages = generatedMessages.slice(-recentMessagesCount);
    const lastSpeakerContext = buildLastSpeakerContext(recentMessages);

    // Track speaker counts
    const speakerCounts = new Map<string, number>();
    generatedMessages.forEach((m) => {
      speakerCounts.set(
        m.deelnemerName,
        (speakerCounts.get(m.deelnemerName) || 0) + 1
      );
    });

    const speakerDistributionContext = buildSpeakerDistributionContext(
      opties.deelnemers,
      speakerCounts
    );

    const userPrompt = buildUserPrompt({
      conversationContext: conversationSummaryContext,
      lastSpeakerContext,
      speakerDistributionContext,
      phase,
      phaseInstructions: phaseInstructions[phase],
      isLastBatch,
    });

    try {
      // Selecteer random model configuratie voor variatie
      const modelConfig = getRandomModelConfig();

      logger.debug(`Calling AI with schema`, {
        schemaStructure:
          "Array of turns, each turn has deelnemerName and messages array",
        modelConfig: modelConfig.name,
        temperature: modelConfig.settings.temperature,
      });

      const response = await generateObject({
        model: modelConfig.model,
        ...modelConfig.settings,
        schema: buildMessageSchema(opties.deelnemers),
        schemaName: "PolitiekeGespreksBeurten",
        schemaDescription:
          "Array van EXACT 2 of 3 politieke gespreksbeurten. Elke beurt bevat de naam van een politicus en hun 1-3 korte berichten. ABSOLUUT MAXIMUM: 3 beurten. Niet 4, niet 5, maximaal 3.",
        mode: "json",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt },
        ],
        // @ts-expect-error - onFinish is not a valid property
        onFinish: ({ response: finishResponse }) => {
          logger.debug(`AI raw response (onFinish)`, {
            text: finishResponse.text,
            finishReason: finishResponse.finishReason,
            modelUsed: modelConfig.name,
          });
        },
      });

      logger.debug(`AI response received successfully`, {
        turnsGenerated: response.object.length,
        rawResponse: JSON.stringify(response.object, null, 2),
      });

      // Truncate naar max turns - AI genereert vaak meer turns ondanks instructies
      const aiMessages =
        response.object.length > MAX_TURNS_TO_USE
          ? response.object.slice(0, MAX_TURNS_TO_USE)
          : response.object;

      if (response.object.length > MAX_TURNS_TO_USE) {
        logger.info(
          `AI generated ${response.object.length} turns, using first ${MAX_TURNS_TO_USE}`,
          {
            generated: response.object.length,
            used: aiMessages.length,
          }
        );
      }

      const newMessages = addDeelnemerIdsToAIGeneratedMessages(
        aiMessages,
        opties.deelnemers
      );

      if (newMessages.length === 0) {
        logger.warn(`No messages generated for batch ${batchCount}`, {
          batchCount,
        });
        break;
      }

      generatedMessages.push(...newMessages);
      logger.debug(
        `Generated ${newMessages.length} messages for batch ${batchCount} (total: ${generatedMessages.length}/${targetMessageCount})`,
        { batchCount, totalMessages: generatedMessages.length }
      );

      if (generatedMessages.length >= targetMessageCount) {
        logger.info(`Target message count reached, stopping generation`);
        break;
      }
    } catch (error) {
      // Log detailed error information including any raw response
      const errorDetails: {
        errorName: string;
        errorMessage: string;
        rawResponse?: unknown;
        rawText?: unknown;
        cause?: unknown;
      } = {
        errorName: error instanceof Error ? error.name : "Unknown",
        errorMessage: error instanceof Error ? error.message : String(error),
      };

      // Try to extract raw response from AI SDK error
      if (error && typeof error === "object") {
        // @ts-expect-error - AI SDK errors may have these properties
        if (error.response) errorDetails.rawResponse = error.response;
        // @ts-expect-error - AI SDK errors may have these properties
        if (error.text) errorDetails.rawText = error.text;
        // @ts-expect-error - AI SDK errors may have these properties
        if (error.cause) errorDetails.cause = error.cause;
      }

      logger.error(
        `Error generating messages for batch ${batchCount}`,
        errorDetails
      );

      if (generatedMessages.length === 0) {
        throw error;
      }
      break;
    }
  }

  logger.info("Gesprek berichten generation completed", {
    totalMessages: generatedMessages.length,
    targetMessages: targetMessageCount,
  });

  return addTimestampsToMessages(
    generatedMessages,
    opties.startAt,
    opties.endAt
  );
}
